{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comet.ml Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: We detected that you are running inside a Ipython/Jupyter notebook environment but we cannot save your notebook source code. Please be sure to have installed comet_ml as a notebook server extension by running:\n",
      "jupyter comet_ml enable \n",
      "For more details, please refer to: https://www.comet.ml/docs/python-sdk/warnings-errors\n",
      "COMET WARNING: Comet.ml support for Ipython Notebook is limited at the moment, automatic monitoring and stdout capturing is deactivated \n",
      "For more details, please refer to: https://www.comet.ml/docs/python-sdk/warnings-errors\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/carlos-quintanilla/sklearn-demos/dede9962241541cb82dde78debefb584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import comet_ml in the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "#create an experiment with your api key\n",
    "exp = Experiment(api_key=\"RIvuxK0v8Wx0yL2SB5gP2WEZs\",\n",
    "  project_name='sklearn-demos',\n",
    "  auto_param_logging=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer.keys(): dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n",
      "Shape of cancer data: (569, 30)\n",
      "\n",
      "Sample counts per class:\n",
      "{'malignant': 212, 'benign': 357}\n",
      "\n",
      "Feature names:\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys(): {}\".format(cancer.keys()))\n",
    "print(\"Shape of cancer data: {}\\n\".format(cancer.data.shape))\n",
    "print(\"Sample counts per class:\\n{}\".format(\n",
    "      {n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))}))\n",
    "print(\"\\nFeature names:\\n{}\".format(cancer.feature_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data,\n",
    "    cancer.target,\n",
    "    stratify=cancer.target,\n",
    "    random_state=random_state)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 5, 10, 20, 50, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C':[0.001,0.01,0.1,1,5,10,20,50,100]}\n",
    "\n",
    "clf = GridSearchCV(logreg,\n",
    "                    param_grid=param_grid,\n",
    "                    cv=10,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results\n",
      "Confusion matrix \n",
      " [[52  1]\n",
      " [ 1 89]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"\\nResults\\nConfusion matrix \\n {}\".format(confusion_matrix(y_test, y_pred)))\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is  0.989\n",
      "Precision score is  0.989\n",
      "Recall score is  0.989\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 score is {:6.3f}\".format(f1))\n",
    "print(\"Precision score is {:6.3f}\".format(precision))\n",
    "print(\"Recall score is {:6.3f}\".format(recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these will be logged to your sklearn-demos project on Comet.ml\n",
    "params={\"random_state\":random_state,\n",
    "        \"model_type\":\"logreg\",\n",
    "        \"scaler\":\"standard scaler\",\n",
    "        \"param_grid\":str(param_grid),\n",
    "        \"stratify\":True\n",
    "}\n",
    "\n",
    "metrics = {\"f1\":f1,\n",
    "\"recall\":recall,\n",
    "\"precision\":precision\n",
    "}\n",
    "\n",
    "exp.log_dataset_hash(X_train_scaled)\n",
    "exp.log_multiple_params(params)\n",
    "exp.log_multiple_metrics(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
